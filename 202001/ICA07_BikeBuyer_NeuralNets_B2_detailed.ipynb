{"cells":[{"cell_type":"code","source":["import pandas as pd\nimport numpy as np\nimport random\nfrom sklearn.preprocessing import StandardScaler"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"code","source":["import tensorflow as tf"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["df= pd.read_csv('/dbfs/FileStore/tables/numericTargetMail.csv') #change filename according to your actual data file\ndf.head()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["def processInputData(df, testing_size = 1000):\n  features = []\n  row, col = df.shape\n  for r in range(row):\n    feature = []\n    for c in range(col-1):\n      feature.append(df.iloc[r,c])\n      if df.iloc[r,col-1] == 1:\n        features.append([feature,[1,0]])\n      else:\n        features.append([feature,[0,1]])\n  random.shuffle(features)\n  features = np.array(features)\n  train_x = list(features[:,0][:len(df)-testing_size])\n  train_y = list(features[:,1][:len(df)-testing_size])\n  test_x = list(features[:,0][-testing_size:])\n  test_y = list(features[:,1][-testing_size:])\n  return train_x, train_y, test_x, test_y\n\ntrain_x,train_y,test_x,test_y = processInputData(df)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"code","source":["sc = StandardScaler()\nsc.fit(train_x)\ntrain_x_std = sc.transform(train_x)\ntest_x_std = sc.transform(test_x)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"code","source":["n_nodes_input_layer = 11 # Number of neurons at input layer\nn_nodes_hl1 = 500        # Number of neurons at hidden layers\nn_nodes_output_layer = 2 # Number of neurons at output layer\n\nbatch_size = 100\n\ntraining_iterations = 20\n\nx = tf.placeholder('float')\ny = tf.placeholder('float')\n\nhidden_1_layer = {'f_fum':n_nodes_hl1,\n                  'weight':tf.Variable(tf.random_normal([n_nodes_input_layer, n_nodes_hl1])),\n                  'bias':tf.Variable(tf.random_normal([n_nodes_hl1]))}\n\noutput_layer = {'f_fum':None,\n                'weight':tf.Variable(tf.random_normal([n_nodes_hl1, n_nodes_output_layer])),\n                'bias':tf.Variable(tf.random_normal([n_nodes_output_layer])),}\n\n\n#define neural network with 1 hidden layer\ndef neural_network_model(data):\n\n    l1 = tf.add(tf.matmul(data,hidden_1_layer['weight']), hidden_1_layer['bias'])\n    l1 = tf.nn.relu(l1)\n\n    output = tf.matmul(l1,output_layer['weight']) + output_layer['bias']\n\n    return output\n  \n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":["def train_NN(x):\n    prediction = neural_network_model(x)\n    cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=y) )\n    optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)\n    conf_matrix = [[0,0],[0,0]]\n    with tf.Session() as sess:\n        sess.run(tf.global_variables_initializer())\n\n        for epoch in range(training_iterations):\n            epoch_loss = 0\n            i=0\n            while i < len(train_x_std):\n                start = i\n                end = i+batch_size\n                batch_x = np.array(train_x_std[start:end])\n                batch_y = np.array(train_y[start:end])\n\n                _, c = sess.run([optimizer, cost], feed_dict={x: batch_x,\n                                                              y: batch_y})\n                epoch_loss += c\n                i+=batch_size\n\n            print('Iteration', epoch+1, 'completed out of',training_iterations,'loss function value:',epoch_loss)\n        correct = tf.equal(tf.argmax(prediction, 1),tf.argmax(y, 1))\n        accuracy = tf.reduce_mean(tf.cast(correct,'float'))\n        yp = tf.cast(tf.argmax(prediction, 1),'float')\n        print('Accuracy:',accuracy.eval({x:test_x_std, y:test_y}))\n        ypred = yp.eval({x:test_x_std, y:test_y})\n        cf = [[0,0],[0,0]]\n        tp = 0\n        tn = 0\n        fp = 0\n        fn = 0\n        for ind in range(len(ypred)):\n            if (ypred[ind] == 1) and (test_y[ind][0] == 1):\n                tp += 1\n            if (ypred[ind] == 1) and (test_y[ind][0] == 0):\n                fp += 1\n            if (ypred[ind] == 0) and (test_y[ind][0] == 1):\n               fn += 1\n            if (ypred[ind] == 0) and (test_y[ind][0] == 0):\n               tn += 1\n        conf_matrix[0][0] = tp\n        conf_matrix[0][1] = fp\n        conf_matrix[1][0] = fn\n        conf_matrix[1][1] = tn\n        print('confusion matrix:',conf_matrix)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"code","source":["train_NN(x)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":8},{"cell_type":"code","source":["#define neural network structure\nn_nodes_input_layer = 11\nn_nodes_hl1 = 250\nn_nodes_hl2 = 250\nn_nodes_output_layer = 2\n\nbatch_size = 100\n\ntraining_iterations = 20\n\nx = tf.placeholder('float')\ny = tf.placeholder('float')\nhidden_1_layer = {'f_fum':n_nodes_hl1,\n                  'weight':tf.Variable(tf.random_normal([n_nodes_input_layer, n_nodes_hl1])),\n                  'bias':tf.Variable(tf.random_normal([n_nodes_hl1]))}\nhidden_2_layer = {'f_fum':n_nodes_hl2,\n                  'weight':tf.Variable(tf.random_normal([n_nodes_hl1, n_nodes_hl2])),\n                  'bias':tf.Variable(tf.random_normal([n_nodes_hl2]))}\noutput_layer = {'f_fum':None,\n                'weight':tf.Variable(tf.random_normal([n_nodes_hl2, n_nodes_output_layer])),\n                'bias':tf.Variable(tf.random_normal([n_nodes_output_layer])),}\n#define neural network model using tensorflow\ndef neural_network_model(data):\n    l1 = tf.add(tf.matmul(data,hidden_1_layer['weight']), hidden_1_layer['bias'])\n    l1 = tf.nn.relu(l1)\n    l2 = tf.add(tf.matmul(l1,hidden_2_layer['weight']), hidden_2_layer['bias'])\n    l2 = tf.nn.relu(l2)\n\n    output = tf.matmul(l2,output_layer['weight']) + output_layer['bias']\n    return output"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":9},{"cell_type":"code","source":["train_NN(x)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":10}],"metadata":{"name":"BikeBuyer","notebookId":3321145723227454},"nbformat":4,"nbformat_minor":0}
